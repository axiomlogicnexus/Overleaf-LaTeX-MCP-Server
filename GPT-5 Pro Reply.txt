Plan and scope

You’re building an Overleaf LaTeX Model Context Protocol (MCP) Server that will broker between an LLM client and Overleaf’s compilation and Git surfaces. Below are: (1) recommended implementation languages with rationale, and (2) a concise catalogue of the Overleaf CLSI and Git surfaces that are commonly available in Overleaf CE/Server/Cloud deployments, followed by pragmatic, MCP-friendly endpoints/hooks I recommend adding.

1) Best-suited programming language(s) for an MCP server

Primary choice: TypeScript (Node.js)

Why: First-class MCP SDK and examples, excellent HTTP/websocket support, strong Git ecosystem (isomorphic-git, nodegit), robust streaming/logging, mature JSON schema tooling, easy cross-platform deployment.

Strengths for this project:

Rapid adapter/tool development for MCP.

Strong libraries for auth, rate limiting, retries, structured logging, and metrics.

Good PDF/zip handling and multipart upload support for CLSI resource payloads.

Strong alternative: Python

Why: Excellent TeX tooling wrappers (latexmk integration, chktex, latexindent), batteries-included HTTP clients/servers (httpx/FastAPI), good Git bindings (GitPython).

Strengths: Quick prototyping, a lot of LaTeX-specific utilities available, straightforward async support via FastAPI/uvicorn.

Secondary options (trade-offs noted):

Go: Simple static binaries, strong concurrency, good HTTP clients/servers; fewer LaTeX- and Git-focused high-level libraries; MCP SDK support is emerging.

Rust: Performance/safety; longest development cycle, fewer ready-made components for quick integration; MCP SDK support is emerging.

Recommended stack for speed and maintainability: TypeScript + MCP SDK + Fastify (or Express) for any optional HTTP ingress (e.g., webhooks), nodegit for Git operations, pino for logs, zod/json-schema for tool validation. If you expect heavy local TeX tooling (lint/format/preflight), add a small Python sidecar for chktex/latexindent and call it from Node.

2) Overleaf CLSI API and Git Integration surfaces

Important notes

Overleaf CLSI (Common LaTeX Service Interface) is typically an internal microservice in Overleaf deployments (CE/Server Pro/Cloud). Some organizations expose it behind an API gateway. Exact paths and fields can vary by version/config.

The Git “API” is standard Git smart HTTP(S) endpoints plus provider integrations (GitHub/GitLab/Bitbucket) via OAuth in Overleaf Server Pro/Cloud. It’s not a typical REST surface, but we can still treat events/operations as “hooks.”

Treat the list below as the common, documented patterns across Overleaf’s open-source services and Cloud. Your deployment may have small differences.

CLSI endpoints (commonly available)

Synchronous compile

POST /compile

Body (typical shape):

compiler: pdflatex | xelatex | lualatex | latexmk

rootResourcePath: path to main .tex

outputFormat: pdf | dvi | ps (usually pdf)

resources: array of resource descriptors:

{ path, content } for inline text (UTF-8)

{ path, url } for remote fetch

optionally { path, fileId } if using prior upload APIs

options (deployment-dependent): synctex, timeout, draft mode, shell-escape policy, bibtex/biber runs

Returns: status (success/error/timeout), outputFiles (PDF, logs, aux, synctex), and possibly a compileId. Some deployments return artifact URLs; others embed base64.

Asynchronous/long-running variant (if enabled)

POST /compile with callback/url or async=true

Returns: compileId immediately.

GET /builds/{compileId} or GET /status/{compileId}

Returns current state, progress, and when done, artifact descriptors.

DELETE /builds/{compileId}

Cancel a running build.

Artifact retrieval (deployment-dependent)

GET /builds/{compileId}/output/{path}

GET /builds/{compileId}/log

Fetch compiled outputs and logs (by file path/type).

Resource pre-upload (optional feature)

POST /resources (multipart)

Upload large/binary resources out-of-band, get fileId(s) to reference in /compile.

DELETE /resources/{fileId}

Remove previously uploaded resources.

Health/ops

GET /health or /_health

GET /version

GET /metrics (Prometheus format, often behind auth)

Common request nuances to expect

Size and timeout limits; max number of resources.

Security constraints: shell-escape disabled by default; network fetch whitelists; memory/CPU quotas.

Bib(la)tex/biber and makeindex runs often controlled by latexmk options.

Overleaf Git integration surfaces

Git over HTTPS (smart HTTP)

Remote URL for a project (Cloud example): https://git.overleaf.com/.git

Auth: Overleaf account + password or personal access token (on Cloud), or LDAP/SAML/SSO in Enterprise.

Operations: clone, fetch, pull, push via standard Git endpoints (info/refs, git-upload-pack, git-receive-pack).

Typical behaviors:

Pushing to the Overleaf remote updates the project files; Overleaf’s UI usually auto-recompiles on change.

Branching: Overleaf behaves like a single main branch in the UI; Git branches exist but the UI primarily tracks default branch content.

Git provider integrations (Overleaf Server Pro/Cloud)

Connect project to GitHub/GitLab/Bitbucket repo (via OAuth).

One-way or two-way sync (pull from provider; push back on demand or on schedule).

Import/export flows initiated in UI; programmatic endpoints are internal/private.

Event surfaces:

On linked repos, pulling changes from provider updates Overleaf and can trigger a recompile.

Pushing from Overleaf to provider (manual or automated) can be configured depending on the product tier.

Existing hooks/events you can rely on operationally

Push to Overleaf remote -> project updates (and typically triggers a compile in UI).

Changes in UI editor -> auto-compile (UI behavior, not a public webhook).

MCP-friendly endpoints and hooks to add (proposed)

Add these to your MCP server (they call Overleaf CLSI/Git under the hood). They are not native Overleaf endpoints; they make Overleaf surfaces first-class for LLM tooling.

CLSI-oriented

mcp.tools.compile_latex

Input: resources[] (content/url), rootResourcePath, compiler, outputFormat, options (synctex, shellEscape policy, timeout).

Output: status, outputFiles (PDF/log/aux as URLs or base64), warnings/errors parsed and structured.

mcp.tools.compile_latex_async

Input: same as above; returns compileId. Provide mcp.events.compile.updated/final via server-sent events over MCP or polling tool mcp.tools.get_compile_status(compileId).

mcp.tools.get_compile_artifact

Input: compileId, path or type (pdf/log/synctex).

mcp.tools.tex_preflight

Input: resources; runs chktex/latexindent/regex sanity checks; Output: actionable diagnostics before compiling.

mcp.tools.tex_outline

Input: root .tex; Output: section/label/ref/citation graph to support LLM navigation.

mcp.tools.bib_resolve

Resolve and validate bibliography tooling (bibtex/biber), report missing entries.

Git-oriented

mcp.tools.git_clone_overleaf

Input: overleaf_git_url, credentials/token, optional shallow/branch; Output: local path (or virtual fs id).

mcp.tools.git_pull_push

Pull latest from Overleaf or push changes back (with conflict policy).

mcp.tools.git_commit_patch

Apply patch to working tree (from LLM suggestions), commit with message, optionally run pre-commit checks.

mcp.tools.git_compile_on_push

Convenience: push to Overleaf then invoke compile_latex; attach status and artifacts to the commit metadata returned to the client.

Event/webhook ingress (optional HTTP service alongside MCP)

POST /webhooks/github | /webhooks/gitlab

Receive provider events (push/PR/MR) -> trigger CLSI compile; emit MCP events compile.updated/final.

POST /webhooks/compile/callback

If using async CLSI with callbacks, receive compile completion and bridge to MCP events.

Operational/observability

GET /health, GET /metrics

Health probes and metrics for your MCP adapter (latency, success rate, cache hit rate).

Cache warmers for LaTeX packages and fonts to reduce cold start time.

Git server hook emulation (proposed behaviors)

pre-receive (emulated): block pushes with forbidden files (large binaries, secrets), require main.tex presence.

post-receive (emulated): auto-run CLSI compile; store artifacts; post a status back to the LLM client or annotate commit.

update (emulated): maintain tags/notes with last successful compile status.

Security and policy surfaces

Secrets management for Overleaf and Git provider tokens; per-project policy on shell-escape, network fetch, and resource size limits.

Rate limiting and circuit breakers around CLSI calls.

Recommended field conventions for MCP tool I/O

All tools accept a project_id or sources descriptor:

sources: { type: "git", url, ref, auth } | { type: "inline", resources[] }

Compile options schema:

{ compiler, outputFormat, synctex: boolean, shellEscape: "off" | "restricted" | "on", timeoutMs, latexmkRc?: string, bibMode?: "bibtex" | "biber" | "auto" }

Artifacts:

Prefer returning small text artifacts inline (log, aux snippets) and provide URLs or temporary object storage for large artifacts (PDF).

Summary

Use TypeScript for the MCP server core; optionally add a Python sidecar for LaTeX lint/format tools.

Overleaf CLSI commonly offers: POST /compile, optional async status/artifact endpoints, and health/metrics; resource pre-upload is sometimes available.

Overleaf Git is standard Git HTTPS remotes plus provider integrations in Server Pro/Cloud; no public REST hooks, but pushes/changes typically trigger recompiles.

Add MCP-oriented tools and emulated hooks to make compilation, artifacts, and Git flows first-class, observable, and policy-controlled for LLM-driven workflows.

Next step: if you want, I can scaffold the MCP server layout (TypeScript), including tool definitions for compile_latex, get_compile_status, git_clone_overleaf, and a minimal Fastify webhook ingress.