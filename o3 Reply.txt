Key points that are easy to overlook when designing a self-hosted “Overleaf-style” LaTeX Management / Compile / Preview (MCP) service:

1. Compile sandboxing and resource limits

• Spawn compiles in an unprivileged container / chroot (Docker, Firecracker, gVisor, etc.).

• Impose hard CPU‐time, memory and wall-clock limits at the kernel / cgroup level, not only in code.

• Mount the project directory read-only inside the sandbox; write output to a tmpfs that is copied out on success.

• Disable shell-escape by default; if you must support it, run an entirely different, more restricted profile.

2. Queueing, parallelism and back-pressure

• A single user pressing “Recompile” can DOS the host if each click spawns a new process.

• Place compile jobs onto a durable queue (Redis, RabbitMQ, or a DB table with advisory locks).

• Deduplicate identical hashes so that rapid recompiles collapse into one job.

• Expose queue length / worker health via Prometheus metrics so autoscalers know when to add capacity.

3. Incremental‐compile cache

• Keep a persistent TEXMF and latexmk aux cache keyed by project hash; copy it into the sandbox to avoid full rebuilds.

• Place cache on an SSD-backed volume separate from user uploads to avoid I/O contention.

4. File-system abstraction and project size limits

• Don’t trust the LaTeX project path supplied by the client; canonicalise and verify it is under the user’s tenant root.

• Enforce a maximum uncompressed project size and a maximum individual file size up-front.

5. Real-time log streaming

• Compile logs grow quickly; stream stdout/err through WebSocket chunks so the browser can tail incrementally.

• Implement ANSI colour stripping on the server and send plain-text + structured JSON diagnostics separately so the UI can highlight errors.

6. Authentication / authorisation

• Separate compile permission from read/write permission; guests may view PDF but not compile.

• All API routes should take a project_id plus a short-lived signed URL or OAuth token, never raw paths.

7. Versioning & rollback

• Store projects in a git-bare repo or a KV store that snapshots on every save; compile from a specific commit SHA so results are reproducible.

• Provide an endpoint to compile “commit N-1” for easy regression hunting.

8. Extensibility hooks

• Provide a plugin interface: after successful compile, emit an event that downstream services (spell-checker, bibliography crawler, plagiarism checker) can subscribe to.

• Keep the contract JSON-schema-validated so external tools don’t break when you add fields.

9. Observability & alerting

• Mandatory structured logging (request-id, user-id, project-id, job-id) at every hop.

• Histogram Prometheus metrics for compile duration, memory, exit code, queue latency.

• Alert on 95-th percentile compile time, worker crashes, queue depth, sandbox kill signals.

10. Deployment & portability

• Ship a docker-compose file that spins up: API Gateway, Web UI, Queue, Workers, DB, Object Storage (e.g., MinIO), Prometheus + Grafana.

• Provide a Helm chart for Kubernetes; use init containers to pre-warm TeXLive layer so worker pods start fast.

• Keep TeXLive distribution as a separate OCI image layer so updates don’t rebuild the whole stack.

11. Security posture

• Never embed user PDF back into the DOM via “data:” URIs; always serve from a private, signed S3/MinIO URL to avoid XSS.

• Strip potentially malicious \write18 or \input|xx commands when shell-escape is disabled.

• Periodically run Trivy or grype scans on the TeXLive image – CVEs do appear.

12. User-experience niceties

• Expose a “dry-run” compile that returns diagnostics only; useful for fast lint checks.

• Auto-select main.tex if the project has exactly one .tex file or contains \documentclass; ask otherwise.

• Provide a REST endpoint to fetch current PDF SHA so the browser cache busts correctly without polling.

13. Documentation & governance

• Document supported TeXLive year and package update policy.

• Publish an SLA for job time-outs and storage quotas.

• Make the roadmap public; encourage community PRs for new packages or tooling.

How these suggestions might fit into your artefacts:

• ARCHITECTURE.md – place bullets 1–4, 8-10 here; add sequence diagrams: Client → API → Queue → Worker → Storage.

• API.md – specify compile/queue endpoints, log streaming over WS, signed URL schema, error codes.

• global_rules.md – include security defaults (no shell-escape, 2 min CPU limit, 512 MiB RAM cap).

• ROADMAP.md – call out milestones: v0.1 local compile; v0.2 queue + cache; v0.3 multi-tenant RBAC; v1.0 production hardening.

If any of these areas are already addressed, great—otherwise consider incorporating them before the implementation solidifies.Provided a checklist of architecture, security, performance and UX concerns—sandboxing, queueing, cache, auth, observability, deployment, etc.—and mapped each to the existing docs (ARCHITECTURE.md, API.md, global_rules.md, ROADMAP.md) so you can fold them into the plan.

Your existing plan is on the right trajectory and the previous AI reviews are mostly in agreement.  Below is a distilled “executive-summary + gap list” that merges the best ideas from all five prior replies and maps them to concrete next actions.

================================================================

1. Architecture (what must exist before any further coding)

----------------------------------------------------------------

• Compile-provider interface

– Interface with at least two implementations:  CLSIProvider and LocalProvider (sandboxed latexmk).

– Pick via project-level config.

• Workspace manager

– Root-confined work dir per project / per session.

– TTL clean-up job.

• Job queue / coalescer

– One queue, priority field, per-project debounce window.

– Worker pool size limit (env or config).

• Artifact store

– Writes PDF/log into tmp/object-store, returns signed URL (not base64).

– GC based on TTL.

• Compile → PDF path

Client → compile_latex(_async) → queue → provider → artifact store → URL in result / event.

================================================================

2. Git workflow (safe for LLM‐driven edits)

----------------------------------------------------------------

• git_start_session   → clones + creates branch mcp-session/UUID

• git_commit_patch    → hash-validated patch; rejects drift

• git_pull_push       → sync with rebase / ff-only policy

• git_propose_merge   → returns merge request link or summary; no force-push

• Policies: block >10 MB binaries, LFS-warn, main.tex required.

================================================================

3. Tool surface (MCP v1)

----------------------------------------------------------------

Core sync/async

compile_latex, compile_latex_async, get_compile_status, cancel_operation

Git

git_start_session, git_commit_patch, git_pull_push, git_propose_merge

LaTeX IQ

tex_outline, tex_preflight, tex_lint (chktex), tex_format (latexindent), analyze_structure

Utility / ops

get_capabilities, get_health, get_metrics

All return structured JSON {status, data, errors[]}.

================================================================

4. Security mandates (align with global_rules.md)

----------------------------------------------------------------

• Path containment check in ONE helper used everywhere.

• spawn(cmd, args, {shell:false}); never shell:true.

• Local compile runs as restricted user / container, network off, shell-escape disabled unless policy says otherwise.

• All external credentials loaded from env/secret store; never printed.

• Log scrubbing middleware masks tokens.

================================================================

5. Observability

----------------------------------------------------------------

• pino JSON logs (request-id, project-id, op-id).

• Prometheus metrics: compile_duration_seconds, compile_memory_bytes, queue_depth, git_sync_errors.

• OpenTelemetry spans around git & compile.

================================================================

6. Documentation automation

----------------------------------------------------------------

• script dev_generate_api_docs pulls tool schemas → writes API.md.

• CHANGELOG.md updated by commit-lint hook (Conventional Commits).

================================================================

7. Roadmap (three hard phases)

----------------------------------------------------------------

Phase 0.1   bootstrap

– Workspace manager, LocalProvider, compile_latex (sync), manual queue ≤1.

Phase 0.2   robust core

– Queue/coalescer, CLSIProvider, compile_async, artifact store, metrics.

Phase 0.3   multi-tenant & git

– Session-branch git flow, conflict detection patch tool, RBAC, per-project policy.

Phase 1.0   production

– Sandboxed containers, rate-limit, autoscale, SLA docs, full test harness with sample projects.

================================================================

Immediate next steps (practical)

----------------------------------------------------------------

1. Create ARCHITECTURE.md with the component diagram & data flow above.

2. Flesh out ROADMAP.md with the phased deliverables.

3. Stub TypeScript interfaces: CompileProvider, WorkspaceManager, JobQueue, ArtifactStore.

4. Add get_capabilities tool that returns available providers & policy so clients can adapt.

5. Wire pino + Prometheus early so telemetry is present from day one.

Once these foundations are in place, adding new high-level tools (cite_lookup, delete_section, etc.) will be straightforward and low-risk.

This covers all major blind spots that appeared across the earlier AI feedback and should put you on a solid path to a secure, production-ready Overleaf MCP server.